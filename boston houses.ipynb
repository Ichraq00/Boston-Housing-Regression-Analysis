{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data information:\n",
    "CRIM: Crime Rate - Per capita crime rate by town\n",
    "ZN: Residential Zone - Proportion of residential land zoned for large lots (over 25,000 sq. ft.)\n",
    "INDUS: Business Zone - Proportion of non-retail business acres per town\n",
    "CHAS: Charles River - Dummy variable (1 if tract bounds river, 0 otherwise)\n",
    "NOX: Nitric Oxides - Concentration of nitric oxides (parts per 10 million)\n",
    "RM: Rooms - Average number of rooms per dwelling\n",
    "AGE: Age - Proportion of owner-occupied units built prior to 1940\n",
    "DIS: Employment Distance - Weighted distances to five Boston employment center\n",
    "RAD: Highway Accessibility - Index of accessibility to radial highways\n",
    "TAX: Property Tax - Full-value property-tax rate per $10,000\n",
    "PTRATIO: Pupil-Teacher Ratio - Pupil-teacher ratio by town\n",
    "B: Black Proportion - Calculated based on the proportion of blacks by town\n",
    "LSTAT: Lower Status - Percentage of lower status of the population\n",
    "MEDV: Median Value - Median value of owner-occupied homes in $1000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping original column names to new column names\n",
    "column_names = {\n",
    "    'CRIM': 'Crime Rate',\n",
    "    'ZN': 'Residential Zone',\n",
    "    'INDUS': 'Business Zone',\n",
    "    'CHAS': 'Charles River',\n",
    "    'NOX': 'Nitric Oxides',\n",
    "    'RM': 'Rooms',\n",
    "    'AGE': 'Age',\n",
    "    'DIS': 'Employment Distance',\n",
    "    'RAD': 'Highway Accessibility',\n",
    "    'TAX': 'Property Tax',\n",
    "    'PTRATIO': 'Pupil-Teacher Ratio',\n",
    "    'B': 'Black Proportion',\n",
    "    'LSTAT': 'Lower Status',\n",
    "    'MEDV': 'Median Value'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "data = data.rename(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for Residential Zone\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data['Residential Zone'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Residential Zone')\n",
    "plt.xlabel('Proportion of Residential Land Zoned for Lots Over 25,000 sq.ft.')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_feature = ['Residential Zone']\n",
    "categorical_feature = ['Charles River','Highway Accessibility']\n",
    "continuous_feature = [feature for feature in data.columns if (feature not in discrete_feature) and (feature not in categorical_feature)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[continuous_feature].describe()\n",
    "#mean is moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of rows and columns for subplots\n",
    "num_rows = len(continuous_feature)\n",
    "num_cols = 2  # One for histogram, one for box plot\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
    "\n",
    "# Iterate through each continuous feature\n",
    "for i, feature in enumerate(continuous_feature):\n",
    "    # Plot histogram\n",
    "    sns.histplot(data=data, x=feature, bins=20, kde=True, color='skyblue', edgecolor='black', ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{feature} Distribution (Histogram)')\n",
    "    axes[i, 0].set_xlabel(feature)\n",
    "    axes[i, 0].set_ylabel('Frequency')\n",
    "\n",
    "    # Plot box plot\n",
    "    axes[i, 1].boxplot(data[feature], vert=False)\n",
    "    axes[i, 1].set_title(f'{feature} Distribution (Box Plot)')\n",
    "    axes[i, 1].set_xlabel(feature)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "Q1 = data['Crime Rate'].quantile(0.25)\n",
    "Q3 = data['Crime Rate'].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the dataset to extract outliers\n",
    "outliers = data[(data['Crime Rate'] < lower_bound) | (data['Crime Rate'] > upper_bound)]\n",
    "\n",
    "# Sort outliers by the 'Crime Rate' column\n",
    "outliers_sorted = outliers.sort_values(by='Crime Rate')\n",
    "\n",
    "# Display outliers as a table\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(outliers_sorted.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "Q1 = data['Rooms'].quantile(0.25)\n",
    "Q3 = data['Rooms'].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the dataset to extract outliers\n",
    "outliers = data[(data['Rooms'] < lower_bound) | (data['Rooms'] > upper_bound)]\n",
    "\n",
    "# Sort outliers by the 'Crime Rate' column\n",
    "outliers_sorted = outliers.sort_values(by='Rooms')\n",
    "\n",
    "# Display outliers as a table\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(outliers_sorted.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "Q1 = data['Black Proportion'].quantile(0.25)\n",
    "Q3 = data['Black Proportion'].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the dataset to extract outliers\n",
    "outliers = data[(data['Black Proportion'] < lower_bound) | (data['Black Proportion'] > upper_bound)]\n",
    "\n",
    "# Sort outliers by the 'Crime Rate' column\n",
    "outliers_sorted = outliers.sort_values(by='Black Proportion')\n",
    "\n",
    "# Display outliers as a table\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(outliers_sorted.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows and columns for subplots\n",
    "num_rows = len(discrete_feature)\n",
    "num_cols = 2  # One for histogram and one for box plot\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
    "\n",
    "# If there's only one feature, adjust the axes array to be 2-dimensional\n",
    "if num_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "# Iterate through each discrete feature\n",
    "for i, feature in enumerate(discrete_feature):\n",
    "    # Plot histogram\n",
    "    sns.histplot(data=data, x=feature, bins='auto', color='skyblue', edgecolor='black', ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{feature} Distribution (Histogram)')\n",
    "    axes[i, 0].set_xlabel(feature)\n",
    "    axes[i, 0].set_ylabel('Frequency')\n",
    "\n",
    "    # Plot box plot\n",
    "    sns.boxplot(data=data, x=feature, ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'{feature} Distribution (Box Plot)')\n",
    "    axes[i, 1].set_xlabel(feature)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows and columns for subplots\n",
    "num_rows = len(categorical_feature)\n",
    "num_cols = 1\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 5*num_rows))\n",
    "\n",
    "# Iterate through each categorical feature\n",
    "for i, feature in enumerate(categorical_feature):\n",
    "    # Plot bar plot\n",
    "    sns.countplot(data=data, x=feature, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} Distribution')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "sns.histplot(data=data,x='Median Value',bins=30,kde=True,color='g')\n",
    "plt.subplot(122)\n",
    "sns.histplot(data=data,x='Median Value',bins=30,kde=True,hue='Charles River')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in continuous_feature+discrete_feature:\n",
    "    # Calculate correlation coefficient\n",
    "    correlation_coefficient = data['Median Value'].corr(data[i])\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.scatter(data['Median Value'], data[i])\n",
    "    plt.title(f\"Scatter Plot {i} (Correlation: {correlation_coefficient:.2f})\")\n",
    "    plt.xlabel('Median Value')\n",
    "    plt.ylabel(i)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Define the number of rows and columns for subplots\n",
    "num_rows = len(categorical_feature)\n",
    "num_cols = 1  # One for box plot\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 5*num_rows))\n",
    "\n",
    "# Iterate through each categorical feature\n",
    "for i, feature in enumerate(categorical_feature):\n",
    "    # Plot box plot\n",
    "    sns.boxplot(data=data, x=feature, y='Median Value', ax=axes[i])\n",
    "    axes[i].set_title(f'Box Plot: {feature} vs Median Value')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Median Value')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Define the number of rows and columns for subplots\n",
    "num_rows = len(discrete_feature)\n",
    "num_cols = 1  # One for box plot\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 5*num_rows), squeeze=False)\n",
    "\n",
    "# Iterate through each discrete feature\n",
    "for i, feature in enumerate(discrete_feature):\n",
    "    # Calculate the row and column index for the current subplot\n",
    "    row_index = i // num_cols\n",
    "    col_index = i % num_cols\n",
    "\n",
    "    # Plot box plot in the correct subplot\n",
    "    sns.boxplot(data=data, x=feature, y='Median Value', ax=axes[row_index, col_index])\n",
    "    axes[row_index, col_index].set_title(f'Box Plot: {feature} vs Median Value')\n",
    "    axes[row_index, col_index].set_xlabel(feature)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Median Value', axis=1)\n",
    "y = data['Median Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting tha dataset into Training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that X_train and X_test are DataFrame\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with your feature scaling setup\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Identify the non-categorical features to scale (replace 'categorical_feature' with the actual feature not to scale)\n",
    "features_to_scale = [col for col in X.columns if col not in categorical_feature]  # Adjust the name as needed\n",
    "\n",
    "# Scale only the non-categorical features\n",
    "X_train_scaled = sc.fit_transform(X_train[features_to_scale])\n",
    "X_test_scaled = sc.transform(X_test[features_to_scale])\n",
    "\n",
    "# Convert scaled arrays back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features_to_scale, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features_to_scale, index=X_test.index)\n",
    "\n",
    "# Concatenate the non-scaled categorical feature back\n",
    "X_train_final = pd.concat([X_train_scaled, X_train[categorical_feature]], axis=1)\n",
    "X_test_final = pd.concat([X_test_scaled, X_test[categorical_feature]], axis=1)\n",
    "\n",
    "# Outputs to see the final data frames\n",
    "print(\"X_train_final head:\", X_train_final.head())\n",
    "print(\"X_test_final head:\", X_test_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_y = StandardScaler()\n",
    "y_train_scaled = sc_y.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test_scaled= sc_y.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Evaluate fonction to give all metrics after model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "def evaluate_model(true,predicted):\n",
    "  mae=mean_absolute_error(true,predicted)\n",
    "  mse=mean_squared_error(true,predicted)\n",
    "  rmse=np.sqrt(mean_squared_error(true,predicted))\n",
    "  r2_square= r2_score(true,predicted)\n",
    "  median_ae = median_absolute_error(true, predicted)\n",
    "  return mae, mse, rmse, r2_square, median_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Dictionary of regression models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Elastic Net\": ElasticNet(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor()\n",
    "}\n",
    "model_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "  model=list(models.values())[i]\n",
    "  model.fit(X_train_final,y_train_scaled)  #train model\n",
    "\n",
    "  #make predictions\n",
    "  y_train_pred = sc_y.inverse_transform(model.predict(X_train_final).reshape(-1, 1))\n",
    "  y_test_pred = sc_y.inverse_transform(model.predict(X_test_final).reshape(-1, 1))\n",
    "\n",
    "  #Evaluate Train and Test dataset\n",
    "  model_train_mae , model_train_mse , model_train_rmse , model_train_r2 , model_train_median_ae = evaluate_model(y_train,y_train_pred)\n",
    "  model_test_mae , model_test_mse , model_test_rmse , model_test_r2 , model_test_median_ae = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "  print(list(models.keys())[i])\n",
    "  model_list.append(list(models.keys())[i])\n",
    "\n",
    "  print(\"Model performance for training set\")\n",
    "  print(\"- Root Mean Squared Error : {:.4f}\".format(model_train_rmse))\n",
    "  print(\"- Mean Absolute Error : {:.4f}\".format(model_train_mae))\n",
    "  print(\"- R2 Score : {:.4f}\".format(model_train_r2))\n",
    "  print(\"- Median Absolute Error : {:.4f}\".format(model_train_median_ae))\n",
    "\n",
    "\n",
    "  print('--------------------------------------------------------------------------------------')\n",
    "\n",
    "  print(\"Model performance for test set\")\n",
    "  print(\"- Root Mean Squared Error : {:.4f}\".format(model_test_rmse))\n",
    "  print(\"- Mean Absolute Error : {:.4f}\".format(model_test_mae))\n",
    "  print(\"- R2 Score : {:.4f}\".format(model_test_r2))\n",
    "  print(\"- Median Absolute Error : {:.4f}\".format(model_test_median_ae))\n",
    "\n",
    "  r2_list.append(model_test_r2)\n",
    "\n",
    "  print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
